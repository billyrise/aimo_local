# =============================================================================
# AIMO Analysis Engine - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values.
# NEVER commit .env to version control.

# -----------------------------------------------------------------------------
# Paths
# -----------------------------------------------------------------------------

# DuckDB database file path
AIMO_DB_PATH=./data/cache/aimo.duckdb

# Working directory for processing (copied from input for atomicity)
AIMO_WORKDIR=./data/work

# Cache directory for signatures and intermediate files
AIMO_CACHE_DIR=./data/cache

# Output directory for reports
AIMO_OUTPUT_DIR=./data/output

# Log directory
AIMO_LOG_DIR=./logs

# -----------------------------------------------------------------------------
# Input Configuration
# -----------------------------------------------------------------------------

# Directory where input files are placed (Box sync destination)
INPUT_DIR=./data/input

# Archive directory for processed files
ARCHIVE_DIR=./data/processed

# -----------------------------------------------------------------------------
# Box Sync (Optional)
# -----------------------------------------------------------------------------

# Enable Box sync integration
BOX_ENABLED=false

# Box folder path to monitor
BOX_INPUT_PATH=/AIMO/inbox

# Seconds to wait for file to stabilize (no size/mtime change)
BOX_STABILIZE_SECONDS=60

# -----------------------------------------------------------------------------
# LLM Configuration
# -----------------------------------------------------------------------------

# Default LLM provider (openai, azure_openai, anthropic)
LLM_PROVIDER=openai

# OpenAI API Key
OPENAI_API_KEY=sk-__REPLACE_WITH_YOUR_KEY__

# Azure OpenAI (if using azure_openai provider)
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_API_KEY=__REPLACE__
AZURE_OPENAI_DEPLOYMENT=gpt-4o-mini

# Anthropic (if using anthropic provider)
ANTHROPIC_API_KEY=__REPLACE__

# Daily budget limit for LLM API calls (USD)
LLM_DAILY_BUDGET_USD=10.0

# Maximum retries for transient errors
LLM_MAX_RETRIES=2

# Request timeout in seconds
LLM_TIMEOUT_SECONDS=30

# -----------------------------------------------------------------------------
# Processing Configuration
# -----------------------------------------------------------------------------

# Signature version (bump when normalization logic changes)
SIGNATURE_VERSION=1.0

# Rule version (bump when base_rules.json changes)
RULE_VERSION=1

# Prompt version (bump when LLM prompts change)
PROMPT_VERSION=1

# -----------------------------------------------------------------------------
# Locking
# -----------------------------------------------------------------------------

# Lock file path for preventing concurrent runs
LOCK_FILE=./data/cache/aimo.lock

# Lock timeout in seconds (fail if lock not acquired within this time)
LOCK_TIMEOUT_SECONDS=60

# -----------------------------------------------------------------------------
# Reporting
# -----------------------------------------------------------------------------

# Salt for sanitized exports (keep secret, never in reports)
SANITIZE_SALT=__REPLACE_WITH_RANDOM_STRING__

# Maximum rows to include in Excel sheets (larger tables use Parquet)
EXCEL_MAX_ROWS=10000

# -----------------------------------------------------------------------------
# Logging
# -----------------------------------------------------------------------------

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Log format (json, text)
LOG_FORMAT=json

# -----------------------------------------------------------------------------
# Development
# -----------------------------------------------------------------------------

# Enable debug mode (verbose logging, skip some validations)
DEBUG_MODE=false

# Git commit hash (automatically set by CI/CD)
CODE_VERSION=dev
